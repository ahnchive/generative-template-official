{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "#from sklearn.manifold import TSNE\n",
    "#from openTSNE import TSNE\n",
    "import umap.umap_ as umap\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of total stimuli:  2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'display_idx': 50,\n",
       " 'display_filename': 'TP_dog_d50',\n",
       " 'condition': 'TP',\n",
       " 'target_label': 'dog',\n",
       " 'target_index': 0,\n",
       " 'clean_objlist': ['../data/imagenet_val_segmented_resized/nontarget/n03980874_ILSVRC2012_val_00017658.JPEG',\n",
       "  '../data/imagenet_val_segmented_resized/nontarget/n04192698_ILSVRC2012_val_00036370.JPEG',\n",
       "  '../data/imagenet_val_segmented_resized/nontarget/n07860988_ILSVRC2012_val_00033051.JPEG',\n",
       "  '../data/imagenet_val_segmented_resized/dog/n02107574_ILSVRC2012_val_00005587.JPEG'],\n",
       " 'foveated_objlist': ['../data/imagenet_val_segmented_resized_foveated/nontarget/TP_dog_d50-b0-n03980874_ILSVRC2012_val_00017658.JPEG',\n",
       "  '../data/imagenet_val_segmented_resized_foveated/nontarget/TP_dog_d50-b1-n04192698_ILSVRC2012_val_00036370.JPEG',\n",
       "  '../data/imagenet_val_segmented_resized_foveated/nontarget/TP_dog_d50-b2-n07860988_ILSVRC2012_val_00033051.JPEG',\n",
       "  '../data/imagenet_val_segmented_resized_foveated/dog/TP_dog_d50-b3-n02107574_ILSVRC2012_val_00005587.JPEG'],\n",
       " 'target_idx_in_objlist': 3,\n",
       " 'bboxlist': [[36, 378, 276, 618],\n",
       "  [378, 773, 618, 1013],\n",
       "  [773, 431, 1013, 671],\n",
       "  [431, 36, 671, 276]],\n",
       " 'blurred_objlist': ['../data/imagenet_val_segmented_resized_blurred/nontarget/blurred-n03980874_ILSVRC2012_val_00017658.JPEG',\n",
       "  '../data/imagenet_val_segmented_resized_blurred/nontarget/blurred-n04192698_ILSVRC2012_val_00036370.JPEG',\n",
       "  '../data/imagenet_val_segmented_resized_blurred/nontarget/blurred-n07860988_ILSVRC2012_val_00033051.JPEG',\n",
       "  '../data/imagenet_val_segmented_resized_blurred/dog/blurred-n02107574_ILSVRC2012_val_00005587.JPEG']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load stimuli info with model priority\n",
    "DIR_STIMULI = '../exp-source/exp_datasource/screen_images/'\n",
    "\n",
    "templates = np.load(\"../checkpoints/template/d_resnet50_ten_template_features_from1000.npz\", allow_pickle=True)['arr_0'].item()\n",
    "\n",
    "display_info =  np.load('../exp-source/display_info.npy', allow_pickle=True)\n",
    "print('# of total stimuli: ', len(display_info))\n",
    "display_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: dog, # of images: 250, Accuracy: 0.58\n",
      "Target: bird, # of images: 250, Accuracy: 0.81\n",
      "Target: turtle, # of images: 250, Accuracy: 0.95\n",
      "Target: insect, # of images: 250, Accuracy: 0.90\n",
      "Results saved for foveated\n"
     ]
    }
   ],
   "source": [
    "IMAGE_TYPE  = 'foveated' # 'blurred', 'foveated', 'clean'\n",
    "#our_results =  np.load(f'../exp-source/our_results_{IMAGE_TYPE}.npy', allow_pickle=True)\n",
    "\n",
    "template_results = []\n",
    "for target in TARGET_CATEGORIES:\n",
    "    display_info_target = list(filter(lambda x: x['target_label'] ==target, display_info))\n",
    "    n_info = len(display_info_target)\n",
    "    acc_sum = 0\n",
    "    n_tp = 0\n",
    "    for i, info in enumerate(display_info_target):\n",
    "        imagepathlist = info[f'{IMAGE_TYPE}_objlist']\n",
    "        features = []\n",
    "        for img_path in imagepathlist:\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "                continue   \n",
    "            img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                feature = model(img_tensor)\n",
    "            feature = feature.view(feature.size(0), -1).cpu().numpy().squeeze()\n",
    "            features.append(feature)      \n",
    "        features = np.array(features)  \n",
    "        target_template = templates[target][0]\n",
    "        distances = np.linalg.norm(features - target_template, axis=1)\n",
    "        probs = softmax(-distances)\n",
    "        if info['condition'] == 'TP':\n",
    "            acc = int(np.argmax(probs) == info['target_idx_in_objlist'])\n",
    "            acc_sum += acc\n",
    "            n_tp += 1\n",
    "        else:\n",
    "            acc = None\n",
    "\n",
    "        d_results = {}\n",
    "        d_results['display_idx'] = info['display_idx']\n",
    "        d_results['display_filename'] = info['display_filename']\n",
    "        d_results['condition'] = info['condition']\n",
    "        d_results['target_label'] = info['target_label']\n",
    "        d_results['objlist'] = imagepathlist\n",
    "        d_results['target_idx_in_objlist'] = info['target_idx_in_objlist']\n",
    "        d_results['L2norm'] = distances\n",
    "        d_results['probs'] = probs\n",
    "        d_results['acc'] = acc\n",
    "\n",
    "        template_results.append(d_results)\n",
    "        #print(features.shape)\n",
    "        #print(target_template.shape)\n",
    "\n",
    "    print(f\"Target: {target}, # of images: {n_tp}, Accuracy: {acc_sum/n_tp:.2f}\")\n",
    "\n",
    "np.save(f'../exp-source/template_results_{IMAGE_TYPE}.npy', template_results)\n",
    "print(f'Results saved for {IMAGE_TYPE}')\n",
    "\n",
    "# Results saved for clean\n",
    "# Target: dog, # of images: 250, Accuracy: 0.64\n",
    "# Target: bird, # of images: 250, Accuracy: 0.87\n",
    "# Target: turtle, # of images: 250, Accuracy: 0.96\n",
    "# Target: insect, # of images: 250, Accuracy: 0.96\n",
    "\n",
    "# Results saved for blurred\n",
    "# Target: dog, # of images: 250, Accuracy: 0.38\n",
    "# Target: bird, # of images: 250, Accuracy: 0.66\n",
    "# Target: turtle, # of images: 250, Accuracy: 0.76\n",
    "# Target: insect, # of images: 250, Accuracy: 0.76\n",
    "\n",
    "# Results saved for foveated\n",
    "# Target: dog, # of images: 250, Accuracy: 0.58\n",
    "# Target: bird, # of images: 250, Accuracy: 0.81\n",
    "# Target: turtle, # of images: 250, Accuracy: 0.95\n",
    "# Target: insect, # of images: 250, Accuracy: 0.90\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wormholes",
   "language": "python",
   "name": "wormholes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
